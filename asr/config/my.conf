[envpath]
KALDI_ROOT = /home/dinghanyu/Documents/kaldi/

[device]
use_gpu = True # use gpu?
appoint_gpu = False
num_gpu = 2
gpu_array = 1, 2, 3, 4


[data]
sample_rate = 16000
frame_length = 0.025
frame_stride = 0.01
low_frequency = 20
high_frequency = 3700
num_utt_per_ark = 1000 # the number of utt in per ark file

[sample]
num_samples_per_ark = 2000 # the number of samples in per ark file
window_size = 300 # the size of sliding window
window_shift = 100 # the shift of sliding window

[train]
train_dir = ./aishell_model/train_logs #train model store path
train_data_file = ./data/aishell_train/feats.scp # train data file path
label_map_file = ./data/aishell_train/label_map # speaker id map
num_frames_file = ./data/aishell_train/num_frames # the number of frames each utt
dev_data_file = ./data/aishell_dev/feats.scp #valid data set
train_log_dir = ./librispeech_log #store train log
dev_accuracy_log = test_accuracy.log #test accuracy log name
dev_trials_symbol = True #whether generate trials
dev_trials_name = libridata_test_trials # dev data trials name
num_dev_utt = 100 # the number of dev utt
num_preload_samples = 1000 # the number of preloading samples
start_learning_rate = 0.0005 #Initial learning rate
end_learning_rate = 0.000005 #The minimal end learning rate
learning_rate_decay_type = exponential #Specifies how the learning rate is decayed. One of "fixed", "exponential", "polynomial"
optimizer = adam #Specifies the optimizer format
momentum = 0.5 #Specifies the momentum param
opt_epsilon = 0.1 #a current good choice is 1.0 or 0.1 in ImageNet example
batch_size = 8 #The number of samples in each batch of training step
small_dataset_test = False #whether doing small dataset test.
num_small_test_batch_size = 32 #number of batch size in small dataset test
num_epochs_per_decay = 1.0 #Number of epochs after which learning rate decays
learning_rate_decay_factor = 0.9 #Learning decay factor
num_epochs = 300 #The number of epochs for training
lstm_hidden_units = 1024 #number of lstm cell hidden untis
lstm_num_layers = 2 #number of lstm layers
feature_dim = 40 #dim of feature
left_context = 7 #number of left context
right_context = 7 #number of right context
lstm_time = 300 #number of frames in lstm (lstm_time = window_size)
cnn_num_filter = 4 #define number of cnn filter, lstm_time must be divided exactly of this number, using in conv2d
cnn_shift_time = 3 #cnn depth stride time, using in conv3d
dvector_dim = 512 #dim of dvector
dropout_rate = 0.5 #probability to keep units in cnn
batch_norm = True #whether doing batch normalization

num_step_store_model = 0 # store model per num_step_store steps

[retrain]
checkpoint = 27014 #train model store step

[produce]
train_dir = ./librispeech_model/train_logs #train model store path
num_speakers = 2191 #equal to number of speaker in train dataset, which is used to restore model
check_point = 219659
test_file = /home/day9011/tensorflow/tensorflow-demo/sre/data/libridata-lda/feats.scp #valid data set
kaldi_prepare_symbol = True #generate trials file
kaldi_prepare_path = /home/day9011/tensorflow/tensorflow-demo/sre/librispeech_log/libridata-lda #generate utt2spk file
utt2spk_suffix = libridata-lda
target_file = libridata-lda-dvector.ark #store dvector file path with kaldi_prepare_path
